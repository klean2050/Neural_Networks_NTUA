{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ow7tTLt0tvmK"
   },
   "source": [
    "# Neural Networks ECE NTUA Course 2019-20 ~ Team M.B.4\n",
    "## Lab Assingment #1: Classification - Study of UCI Datasets - Small (S05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A1G_zo9MtvmL"
   },
   "source": [
    "### A. The Team\n",
    "* Αβραμίδης Κλεάνθης   ~ 03115117\n",
    "* Κρατημένος Άγγελος   ~ 03115025\n",
    "* Πανίδης Κωνσταντίνος ~ 03113602"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HSDaHyfUtvmN"
   },
   "source": [
    "### B. The Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zYugQ6NQtvmO"
   },
   "source": [
    "#### 1. Introduction\n",
    "\n",
    "Το dataset δημιουργήθηκε σε ένα πανεπιστημιακό νοσοκομείο της Πορτογαλίας και περιέχει διάφορα δημογραφικά, εργαστηριακά και άλλα χαρακτηριστικά και ρίσκη σχετικά με την Ιατρική. Τα δεδομένα συλλέχθηκαν από 165 ασθενείς που είχαν διαγνωστεί με HCC. Σύμφωνα με το documentation, κάθε δείγμα περιέχει 49 χαρακτηριστικά, επιλεγμένα σύμφωνα με το *EASL-EORTC (European Association for the Study of the Liver - European Organisation for Research and Treatment of Cancer) Clinical Practice Guidelines*, που είναι το state-of-the-art στη διαχείριση του HCC. Πρόκειται για ένα ετερογενές σύνολο δεδομένων, με 23 ποσοτικές και 23 ποιοτικές μεταβλητές. Συνολικά, οι απουσιάζουσες τιμές εκπροσωπούν το 10.22% του συνόλου των τιμών και μόνο 8 ασθενείες είχαν πλήρεις πληροφορίες. Τα labels είναι η επιβίωση μέχρι και διάστημα ενός έτους και κωδικοποείται με 0 (die) και 1 (lives). Υπάρχει σε ένα βαθμό class-imbalance (102 out of 165 cases alive). Περισσότερα στο *Santos et al. \"A new cluster-based oversampling method for improving survival prediction of hepatocellular carcinoma patients\", Journal of biomedical informatics, 58, 49-59, 2015*. Παρακάτω θα επιβεβαιώσουμε αυτά τα στοιχεία."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eZCq8E9qtvmQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support,f1_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nMkEreXBtvmP"
   },
   "source": [
    "#### 2. Samples & Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CmksyFOdtvmU",
    "outputId": "6a20c55e-069b-4380-c9ce-5c9b438e4cc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dataset contains 165 samples, 49 features and a label.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"hcc-data.txt\",header=None).to_numpy()\n",
    "print(\"The Dataset contains\",data.shape[0],\"samples,\",data.shape[1]-1,\"features and a label.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PWzfv3V-tvmX"
   },
   "source": [
    "Προκύπτει ότι το Dataset αποτελείται από 165 δείγματα, καθένα εκ των οποίων έχει 49 χαρακτηριστικά συν την binary ετικέτα του. Στη συνέχεια θα εξετάσουμε το είδος των χαρακτηριστικών μέσω ενός δείγματος που δεν έχει απουσιάζουσες τιμές:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "kZvoxT4-tvmY",
    "outputId": "b8b94cfa-b473-4182-cd6b-b4da49e987d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of features: {<class 'int'>, <class 'str'>}\n",
      "Inspection of features: [1 '0' 1 '1' '0' '1' '0' 1 '0' '1' '0' '0' '0' '1' '1' '0' '0' '0' '0' '1'\n",
      " '0' '1' '1' 78 '50' '50' 2 '1' '2' '0.96' '5.8' '8.9' '79.8' '8.4' '472'\n",
      " '3.3' '0.4' '58' '68' '202' '109' '7' '2.1' '5' '13' '0.1' '28' '6' '16'\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "clean = [item for item in range(len(data)) if '?' not in data[item]]\n",
    "print(\"Data types of features:\",set([type(feature) for feature in data[clean[0]]]))\n",
    "print(\"Inspection of features:\",data[clean[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YmVDJHmVtvmc"
   },
   "source": [
    "Παρατηρούμε πως όλα τα χαρακτηριστικά λαμβάνουν αριθμητικές float τιμές και δεν υπάρχουν μη διατεταγμένες μορφές. Ωστόσο, τα στοιχεία είναι καταχωρημένα με τύπους int και str. Τροποποιούμε το Dataset ώστε όλα τα στοιχεία μας να είναι τύπου float. Ειδικά για τις απουσιάζουσες τιμές, αντικαθιστούμε το '?' με την τιμή -1, λαμβάνοντας υπόψη ότι όλα τα χαρακτηριστικά λαμβάνουν θετικές τιμές."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "zi2--nP2tvmd",
    "outputId": "0b9b00bc-203e-49f5-e5f4-2d30a0679cbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: [0 '?' 0 '0' '0' '0' '1' 1 '?' '?' '1' '0' '0' '1' '0' '0' '0' '1' '0' '0'\n",
      " '0' '0' '1' 62 '0' '?' 0 '1' '1' '?' '?' '?' '?' '?' '?' '?' '?' '?' '?'\n",
      " '?' '?' '?' '?' '1' '1.8' '?' '?' '?' '?' 1]\n",
      "After: [0 -1 0 '0' '0' '0' '1' 1 -1 -1 '1' '0' '0' '1' '0' '0' '0' '1' '0' '0'\n",
      " '0' '0' '1' 62 '0' -1 0 '1' '1' -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " '1' '1.8' -1 -1 -1 -1 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Before:\",data[1])\n",
    "data = np.where(data=='?',-1,data)\n",
    "print(\"After:\",data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P3_Qk7s-tvmg"
   },
   "source": [
    "#### 3. Documentation\n",
    "\n",
    "Το αρχείο δεδομένων δεν περιέχει επικεφαλίδες, ως εκ τούτου αρκούμαστε στην περιγραφή που περιέχεται στο συνοδευτικό αρχείο και παρουσιάστηκε παραπάνω. Για το λόγο αυτό χρησιμοποιήθηκε στο διάβασμα του αρχείου δεδομένων η παράμετρος\n",
    "```python\n",
    "header = None\n",
    "```\n",
    "καθώς σε αντίθετη παρίπτωση το πρώτο δείγμα θα είχε διαβαστεί ως επικεφαλίδα. Το αρχείο δεν περιέχει αρίθμηση γραμμών, ωστόσο αυτή λαμβάνεται άμεσα από την οργάνωση του αρχείου δεδομένων σε μορφή πίνακα."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uRbfWp-htvmh"
   },
   "source": [
    "#### 4. Labels\n",
    "\n",
    "Σύμφωνα με το documentation, οι ετικέτες των δειγμάτων λαμβάνουν τις τιμές 0 (...) ή 1 (...) και βρίσκονται στην τελευταία κολόνα του πίνακα ```data```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qznJvk_Ltvmj",
    "outputId": "e8f4c0d5-4d63-4f1f-aed3-27ae0c6bd726"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels of the Dataset: {0, 1}\n"
     ]
    }
   ],
   "source": [
    "labels = data[:,-1]\n",
    "feats  = data[:,:-1]\n",
    "print(\"Labels of the Dataset:\",set(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pnsAkGhVtvmm"
   },
   "source": [
    "#### 5. Pre-Processing\n",
    "\n",
    "Δεν απαιτήθηκε κάποια προσαρμογή των input files. Ωστόσο απαιτείται κατάλληλη διαχείριση των τύπων δεδομένων και των απουσιάζουσων τιμών."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T75xi6xktvmn"
   },
   "source": [
    "#### 6. Missing Values\n",
    "\n",
    "Σύμφωνα με το documentation, μόνο 8 δείγματα είναι πλήρη χαρακτηριστικών, ενώ συνολικά οι μη διαθέσιμες τιμές εκπροσωπούν περίπου το 10% των τιμών στο Dataset. Καταρχάς επαληθεύουμε τα ανωτέρω στοιχεία:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "9bQP8C6Stvmo",
    "outputId": "9758ed93-7fd3-4b36-bc08-a8e760d1d6bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8 samples without missing values.\n",
      "826 out of 8085 values in the Dataset are missing. That is 10.216 %\n"
     ]
    }
   ],
   "source": [
    "dirty = [item.tolist().count(-1) for item in feats]\n",
    "total = len(feats)*len(feats[0])\n",
    "\n",
    "print(\"There are\",len(clean),\"samples without missing values.\")\n",
    "print(sum(dirty),\"out of\",total,\"values in the Dataset are missing. That is\",np.round(100*sum(dirty)/total,3),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zkf8al7Vtvmr"
   },
   "source": [
    "Η πιο απλή τεχνική διαχείρισης αυτών των τιμών είναι η αγνόηση των αντίστοιχων δειγμάτων, ωστόσο στην περίπτωσή μας που η συντριπτική πλειοψηφία των δειγμάτων έχει απουσιάζουσες τιμές, η λύση αυτή δεν είναι λειτουργική. Μια άλλη τεχνική είναι η αγνόηση συγκεκριμένων features, που στα περισσότερα δείγματα απουσιάζουν και ως εκ τούτου δεν θα έχουν σημαντική συνεισφορά στο classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ld9ypkaatvms",
    "outputId": "9c48680c-e8c8-4478-bb40-eb32c5cc2e96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "rub_feats = np.zeros((50,1))\n",
    "for feature in range(len(feats[0])): rub_feats[feature] = sum(feats[:,feature]==-1)\n",
    "print(rub_feats[rub_feats>len(feats)/2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6s4V8mDntvmv"
   },
   "source": [
    "Βλέπουμε πως κανένα χαρακτηριστικό δεν απουσιάζει σε πάνω από τα μισά δείγματα, επομένως αγνοώντας κάποιο, σίγουρα θα απωλέσουμε χρήσιμη πληροφορία. Εφόσον λοιπόν δε μπορούμε να αγνοήσουμε τις απουσιάζουσες τιμές, θα πρέπει να τις αντικαταστήσουμε κατάλληλα. Θα αξιοποιήσουμε τον Imputer της Scikit-learn προκειμένου να αντικατασταθούν οι απουσιάζουσες τιμές με τις μέσες τιμές που εμφανίζονται στο εκάστοτε feature, αφού όμως προηγηθεί ο διαχωρισμός στο Βήμα 8. Κι αυτό γιατί, στην αντίθετη περίπτωση, θα υπήρχε η στρέβλωση του να επιδρούν στο train set τιμές από δείγματα που θα καταλήξουν εν τέλει στο test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dTtdAdKQtvmw"
   },
   "source": [
    "#### 7. Balance\n",
    "\n",
    "Λόγω της binary φύσης των labels, μπορούμε να εκτιμήσουμε απευθείας πόσα στοιχεία ανήκουν σε κάθε κλάση μέσω της συνάρτησης sum(), άρα και να αποφανθούμε περί της ισορροπίας του Dataset, διαιρώντας με τον συνολικό αριθμό των δειγμάτων:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "LFHW8kMGtvmx",
    "outputId": "45b4b296-114c-478a-bd01-2af3a6f532ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 samples are alive and 63 are dead\n",
      "The balance of the Dataset is 61.82 % in favor of the alive samples.\n"
     ]
    }
   ],
   "source": [
    "print(sum(labels),\"samples are alive and\",len(labels)-sum(labels),\"are dead\")\n",
    "print(\"The balance of the Dataset is\",round(100*sum(labels)/len(labels),2),\"% in favor of the alive samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7lTtXVUjtvm0"
   },
   "source": [
    "Είναι εμφανές πως τα δεδομένα κλίνουν κατά ένα βαθμό στην κλάση 1, συνεπώς τα δεδομένα μας δεν είναι καλώς ισορροπημένα. Παρότι το ποσοστό παραμένει μικρότερο από 2/3 και θα μπορούσαμε να μην κάνουμε κάτι επιπλέον, επιλέγουμε να εφαρμόσουμε oversampling, θεωρώντας ότι όσο πιο ισορροπημένο είναι το dataset, τόσο καλύτερα θα είναι τα αποτελέσματα. Για να γίνει αυτό θα προηγηθεί το split και να διορθωθούν τα missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sAuTV-Lltvm1"
   },
   "source": [
    "#### 8. Train & Test Set\n",
    "\n",
    "Σαν τελευταίο βήμα επεξεργασίας, θα χωρίσουμε τα δεδομένα σε train και test μέσω της αντίστοιχης συνάρτησης *train_test_split()* της Scikit-learn. Αντίστοιχα χωρίζουμε και τα labels. Επιλέγουμε σχήμα 20% για το test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wsC-qQ4atvm2"
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(feats,labels.astype(int),test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WPUmmsZatvm5"
   },
   "source": [
    "Μπορούμε τώρα να προχωρήσουμε στην αντικατάσταση των missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "O7rEDVKAtvm6",
    "outputId": "0229e7fb-6d0c-4ded-85f2-f6a55953d79a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      " [1 -1 0 '0' '0' '0' '1' 1 -1 '1' '1' '0' '0' '1' '0' '0' '0' '0' '1' '0'\n",
      " '0' '0' '1' 57 '0' -1 0 -1 -1 '1.1' '2.9' '16.4' '94.8' '4.6' '94000'\n",
      " '4.1' '1.1' '104' '74' '88' '85' '7.9' '1.05' '1' '5.5' '0.3' -1 -1 -1]\n",
      "\n",
      "After:\n",
      " [    1.       0.62     0.       0.       0.       0.       1.       1.\n",
      "     0.08     1.       1.       0.       0.       1.       0.       0.\n",
      "     0.       0.       1.       0.       0.       0.       1.      57.\n",
      "     0.      22.52     0.       1.18     1.48     1.1      2.9     16.4\n",
      "    94.8      4.6  94000.       4.1      1.1    104.      74.      88.\n",
      "    85.       7.9      1.05     1.       5.5      0.3     84.25    36.29\n",
      "   438.98]\n",
      "\n",
      "Only float items!\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "imp = SimpleImputer(missing_values=-1,strategy='mean')\n",
    "# ξεχωριστά ώστε να μην παίρνει πληροφορία το ένα σετ από το άλλο\n",
    "print(\"Before:\\n\",x_train[0],end=\"\\n\\n\")\n",
    "x_train = imp.fit_transform(x_train)\n",
    "x_test  = imp.fit_transform(x_test)\n",
    "print(\"After:\\n\",np.round(x_train[0],2),end=\"\\n\\n\")\n",
    "\n",
    "if (x_train==x_train.astype(float)).all() and (x_test==x_test.astype(float)).all(): print(\"Only float items!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hc34Pn7Ttvm9"
   },
   "source": [
    "Κάνουμε τη διαδικασία ξεχωριστά για κάθε σετ και παρατηρούμε πως πλέον όλα τα στοιχεία είναι float. Ως τελευταίο βήμα, θα εφαρμόσουμε oversampling ούτως ώστε να εξισορροπήσουμε το dataset, όπως προείπαμε. Η έννοια του oversampling ειναι πρακτικά η επανάληψη samples από την υπολείπουσα κλάση, ώστε ο λόγος τους να τείνει προς το ιδανικό 50%. Θα εφαρμόσουμε για αυτό το σκοπό την συνάρτηση της Scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BK2Cfb6rtvm-",
    "outputId": "d2d9929a-db64-4da7-9038-0b660dee5deb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The balance of the train set is 0.5\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state = 0)\n",
    "x_train_resampled, y_train_resampled = ros.fit_sample(x_train,y_train)\n",
    "balance = sum(y_train_resampled)/len(y_train_resampled)\n",
    "print(\"The balance of the train set is\",balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C8FfIxoVtvnB"
   },
   "source": [
    "Παρατηρούμε την απευθείας βελτίωση στο λόγο των 2 κλάσεων. Σημειώνουμε πως επιλέγουμε να ισορροπήσουμε μόνο τα δεδομένα εκπαίδευσης, τα οποία είναι και τα μόνα που οφείλουν να είναι ισορροπημένα. Γενικώς αποφεύγουμε οποιαδήποτε περαιτέρω επεξεργασία στα test δεδομένα."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fiGsgNdstvnC"
   },
   "source": [
    "### C. Baseline Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BNPJOvt4tvnD"
   },
   "source": [
    "#### 1. Classification & Metrics\n",
    "\n",
    "Ορίζουμε μία συνάρτηση που εκπαιδεύει τους dummy classifiers με default τιμές και επιστρέφει σε dictionary τα predictions κάθε ταξινομητή, την ακρίβεια του καθώς και τους χρόνους fit και train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j-9t0-pdtvnH"
   },
   "outputs": [],
   "source": [
    "def DummyClassification(x_train,y_train,x_test,y_test):\n",
    "    \n",
    "    scores, predictions, fit_times, pred_times = {}, {}, {}, {}\n",
    "\n",
    "    ### Initialization ###\n",
    "    \n",
    "    dc_uniform  = DummyClassifier(strategy=\"uniform\")\n",
    "    dc_const_0  = DummyClassifier(strategy=\"constant\",constant=0)\n",
    "    dc_const_1  = DummyClassifier(strategy=\"constant\",constant=1)\n",
    "    dc_stratif  = DummyClassifier(strategy=\"stratified\")\n",
    "    dc_frequent = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "    ### Fit ###\n",
    "    \n",
    "    start_time = time.time()\n",
    "    dc_uniform.fit(x_train, y_train)\n",
    "    fit_times['uniform'] = time.time()-start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    dc_const_0.fit(x_train, y_train)\n",
    "    fit_times['const_0'] = time.time()-start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    dc_const_1.fit(x_train, y_train)\n",
    "    fit_times['const_1'] = time.time()-start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    dc_stratif.fit(x_train, y_train)\n",
    "    fit_times['stratif'] = time.time()-start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    dc_frequent.fit(x_train,y_train)\n",
    "    fit_times['frequent'] = time.time()-start_time\n",
    "    \n",
    "    ### Predict ###\n",
    "    \n",
    "    start_time = time.time()\n",
    "    predictions['uniform']  = dc_uniform.predict(x_test)\n",
    "    pred_times['uniform'] = time.time()-start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    predictions['const_0']  = dc_const_0.predict(x_test)\n",
    "    pred_times['const_0'] = time.time()-start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    predictions['const_1']  = dc_const_1.predict(x_test)\n",
    "    pred_times['const_1'] = time.time()-start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    predictions['stratif']  = dc_stratif.predict(x_test)\n",
    "    pred_times['stratif'] = time.time()-start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    predictions['frequent'] = dc_frequent.predict(x_test)\n",
    "    pred_times['frequent'] = time.time()-start_time\n",
    "\n",
    "    ### Score ###\n",
    "    \n",
    "    scores['uniform']  = dc_uniform.score(x_test, y_test)\n",
    "    scores['const_0']  = dc_const_0.score(x_test, y_test)\n",
    "    scores['const_1']  = dc_const_1.score(x_test, y_test)\n",
    "    scores['stratif']  = dc_stratif.score(x_test, y_test)\n",
    "    scores['frequent'] = dc_frequent.score(x_test,y_test)\n",
    "    \n",
    "    return predictions, scores, fit_times, pred_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 763
    },
    "colab_type": "code",
    "id": "Q6Kc3ZXdtvnL",
    "outputId": "d366ad40-4532-42b0-8238-84496b668517",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy of Dummy Classifiers for the test set:\n",
      "\n",
      "With uniform strategy: 60.606 %\n",
      "With const_0 strategy: 39.394 %\n",
      "With const_1 strategy: 60.606 %\n",
      "With stratif strategy: 60.606 %\n",
      "With frequent strategy: 60.606 %\n",
      "\n",
      "Confusion Matrices of Dummy Classifiers for the test set:\n",
      "\n",
      "With uniform strategy:\n",
      " [[ 5  8]\n",
      " [11  9]]\n",
      "With const_0 strategy:\n",
      " [[13  0]\n",
      " [20  0]]\n",
      "With const_1 strategy:\n",
      " [[ 0 13]\n",
      " [ 0 20]]\n",
      "With stratif strategy:\n",
      " [[ 4  9]\n",
      " [ 7 13]]\n",
      "With frequent strategy:\n",
      " [[ 0 13]\n",
      " [ 0 20]]\n",
      "\n",
      "Classification Report of uniform strategy:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.38      0.34        13\n",
      "           1       0.53      0.45      0.49        20\n",
      "\n",
      "    accuracy                           0.42        33\n",
      "   macro avg       0.42      0.42      0.42        33\n",
      "weighted avg       0.44      0.42      0.43        33\n",
      "\n",
      "\n",
      "Classification Report of const_0 strategy:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      1.00      0.57        13\n",
      "           1       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.39        33\n",
      "   macro avg       0.20      0.50      0.28        33\n",
      "weighted avg       0.16      0.39      0.22        33\n",
      "\n",
      "\n",
      "Classification Report of const_1 strategy:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.61      1.00      0.75        20\n",
      "\n",
      "    accuracy                           0.61        33\n",
      "   macro avg       0.30      0.50      0.38        33\n",
      "weighted avg       0.37      0.61      0.46        33\n",
      "\n",
      "\n",
      "Classification Report of stratif strategy:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.31      0.33        13\n",
      "           1       0.59      0.65      0.62        20\n",
      "\n",
      "    accuracy                           0.52        33\n",
      "   macro avg       0.48      0.48      0.48        33\n",
      "weighted avg       0.50      0.52      0.51        33\n",
      "\n",
      "\n",
      "Classification Report of frequent strategy:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.61      1.00      0.75        20\n",
      "\n",
      "    accuracy                           0.61        33\n",
      "   macro avg       0.30      0.50      0.38        33\n",
      "weighted avg       0.37      0.61      0.46        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions, small_accuracies, _, _ = DummyClassification(x_train,y_train,x_test,y_test)\n",
    "\n",
    "print(\"Classification Accuracy of Dummy Classifiers for the test set:\\n\")\n",
    "for strategy in small_accuracies: print(\"With\",strategy,\"strategy:\",np.round(100*small_accuracies[strategy],3),\"%\")\n",
    "\n",
    "print(\"\\nConfusion Matrices of Dummy Classifiers for the test set:\\n\")\n",
    "for strategy in predictions: print(\"With\",strategy,\"strategy:\\n\",confusion_matrix(y_test,predictions[strategy]))\n",
    "\n",
    "for strategy in predictions:\n",
    "    print(\"\\nClassification Report of\",strategy,\"strategy:\\n\",classification_report(y_test,predictions[strategy]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oMYfDV9MzWD5"
   },
   "source": [
    "Εκπαιδεύουμε τώρα έναν baseline 1-NN ταξινομητή:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "NOa2VJsFtvnO",
    "outputId": "385f9648-fa69-4d76-feee-09a18cb16e98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy of 1-NN: 66.667 %\n",
      "\n",
      "Confusion Matrix of 1-NN:\n",
      " [[ 5  8]\n",
      " [ 3 17]]\n",
      "\n",
      "Classification Report of 1-NN:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.38      0.48        13\n",
      "           1       0.68      0.85      0.76        20\n",
      "\n",
      "    accuracy                           0.67        33\n",
      "   macro avg       0.65      0.62      0.62        33\n",
      "weighted avg       0.66      0.67      0.65        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1) \n",
    "knn.fit(x_train,y_train)\n",
    "predictions['knn'] = knn.predict(x_test)\n",
    "small_accuracies['knn'] = knn.score(x_test,y_test)\n",
    "\n",
    "print(\"Classification Accuracy of 1-NN:\",np.round(100*small_accuracies['knn'],3),\"%\")\n",
    "print(\"\\nConfusion Matrix of 1-NN:\\n\",confusion_matrix(y_test,predictions['knn']))\n",
    "print(\"\\nClassification Report of 1-NN:\\n\",classification_report(y_test,predictions['knn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u-gPFYfWtvnT"
   },
   "source": [
    "#### 2. Bar Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "colab_type": "code",
    "id": "K4lTcBe5tvnU",
    "outputId": "1c1a0825-7ed0-4468-fe11-2779bd7ae23a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1_macros, f1_micros, labels = [],[],[]\n",
    "for clf in predictions:  \n",
    "    f1_micros.append(f1_score(y_test,predictions[clf],average='micro'))\n",
    "    f1_macros.append(f1_score(y_test,predictions[clf],average='macro'))\n",
    "    labels.append(clf)\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, f1_micros, width, label='f1_micros')\n",
    "rects2 = ax.bar(x + width/2, f1_macros, width, label='f1_macros')\n",
    "\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Performance Comparison on F1-Score')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jJ9v7C7KtvnY",
    "outputId": "b551f94f-b438-4c0b-9f3e-8ea942156c25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The balance of the test set is 60.6 % in favor of the alive samples.\n"
     ]
    }
   ],
   "source": [
    "print(\"The balance of the test set is\",round(100*sum(y_test)/len(y_test),1),\"% in favor of the alive samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c9of_XzhtvnX"
   },
   "source": [
    "* Μεταξύ των dummy ταξινομητών, η καλύτερη στρατηγική είναι να διαλέγουμε πάντοτε την πιο συχνή κλάση (frequent) ή ισοδύναμα σταθερά την κλάση που είναι η πιο συχνή (constant-1), μιας και το test set δεν είναι ισορροπημένο, όπως φαίνεται παραπάνω.\n",
    "* Εαν δοκιμάσουμε πολλά runs, θα παρατηρήσουμε ότι η επιλογή stratified, δηλαδή να επιλέγουμε τυχαία κλάση διατηρώντας την κατανομή των κλάσεων στο training set, ενώ στη γενική περίπτωση δίνει καλύτερα αποτελέσματα από τη random επιλογή, στη προκειμένη, λόγω της ισορροπίας του train dataset, οι δύο μέθοδοι είναι ισοδύναμες. \n",
    "* Ο k-NN ταξινομητής δίνει καλύτερο αποτέλεσμα από τους dummy classifiers, αφού βασίζεται σε έναν αλγόριθμο λογικής ανάλυσης των δεδομένων. Παρόλ' αυτά, το dataset παραμένει μικρό και οι εκάστοτε γείτονες δεν είναι αντιπορσωπευτικοί, κάτι που περιορίζει τις δυνατότητες του ταξινομητή."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s2HAdTuztvnc"
   },
   "source": [
    "### D. Optimization of Classifiers\n",
    "\n",
    "Θα ακολουθήσουμε bottom-up λογική και επιλέγουμε τον classifier που μπορεί να δώσει καλύτερα αποτελέσματα. Εδώ δεν έχουμε παρά να επιλέξουμε τον k-NN classifier, μιας και οι dummy classifiers δεν επηρεάζονται από την εσωτερική επεξεργασία των δεδομένων. Για την εύρεση των βέλτιστων υπερπαραμέτρων θα διατηρήσουμε το διαχωρισμό του dataset σε 80% train και 20% test και θα χρησιμοποιήσουμε 10-fold cross validation για να εκτιμήσουμε τις παραμέτρους μόνο από το train set. Συγκεκριμένα, αφού γίνει η απαραίτητη προεπεξεργασία ολόκληρου του set, αυτό θα χωριστεί σε 10 subsets, καθένα από τα οποία θα δοκιμαστεί σαν validation set. Στη συνέχεια, οι παράμετροι θα δώσουν το καλύτερο cross score θα εφαρμοστούν προκειμένου να κάνουμε το τελικό prediction για το αρχικό μας test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KHov7-cxtvnd"
   },
   "source": [
    "#### 1-2. Pre-Processing - Optimization and Execution Time\n",
    "\n",
    "Μια απλή τεχνική επιλογής χαρακτηριστικών είναι το ελάχιστο κατώφλι της διακύμανσης (Variance threshold). Γενικώς αν η διακύμανση ενός χαρακτηριστικού είναι χαμηλή, δεν μπορεί να προσφέρει σημαντικά στη διαχωριστική ικανότητα του ταξινομητή. Ειδικά στην περίπτωση που η διακύμανση είναι 0, δηλαδή το χαρακτηριστικό εχει σταθερή τιμή για όλα τα δείγματα εκπαίδευσης, δεν χρησιμέυει καθόλου. Χρησιμοποιούμε την συνάρτηση VarianceThreshold() για να αφαιρέσουμε τα χαρακτηριστικά που έχουν πολύ χαμηλή διακύμανση (κάτω από ένα κατώφλι). Πρέπει επίσης να πάρουμε μια μάσκα (index) των χαρακτηριστικών που επιλέγουμε, ώστε να την εφαρμόσουμε και στο test set, ώστε να έχουν τις ίδιες διαστάσεις.\n",
    "\n",
    "Επίσης, χαρακτηριστικά με πολύ μεγάλες διαφορές στις τιμές τους μπορούν να προκαλέσουν προβλήματα στην εκπαίδευση. Για παράδειγμα ένα χαρακτηριστικό με πολύ μεγάλες τιμές θα έχει μεγαλύτερη επίδραση στον υπολογισμό της απόστασης στον kNN από ότι ένα με μικρές τιμές, χωρίς αυτό να σημαίνει απαραίτητα ότι είναι περισσότερο καθοριστικό. Η κανονικοποίηση μετασχηματίζει τις τιμές των χαρακτηριστικών ώστε να αμβλυνθούν αυτές οι διαφορές και μπορεί να γίνει με 2 τρόπους: Διαιρώντας με τη διαφορά μεγίστου-ελαχίστου (feature scaling) οπότε οι τιμές όλων των χαρακτηριστικών κλιμακώνονται γραμμικά στο διάστημα [0,1] ή με το standard score του κάθε χαρακτηριστικού, που κάνει το χαρακτηριστικό να έχει μέση τιμή μηδέν και διακύμανση μονάδα. H μετατροπή σε standard score είναι απαραίτητη σε πολλούς ταξινομητές για να συμπεριφερθούν σωστά. Επίσης είναι πιο ανθεκτική από την min-max σε σποραδικές τιμές που είναι πολύ μακριά απο τη μέση τιμή και τις υπόλοιπες τιμές του χαρακτηριστικού. Από την άλλη, η κλιμάκωση στο [0,1] είναι λιγότερο ευαίσθητη σε μικρές αποκλίσεις και επίσης σε αραιά διανύσματα διατηρεί τα μηδέν.\n",
    "\n",
    "Εναλλακτικά της επιλογής χαρακτηριστικών με στόχο τη μείωση της διαστατικότητάς τους, μπορούμε να κάνουμε εξαγωγή νέων χαρακτηριστικών σε ένα χώρο μικρότερων διαστάσεων. Η βασικότερη τεχνική feature extraction είναι η ανάλυση σε κύριες συνιστώσες (PCA) όπου αναλύουμε τα δεδομένα σε κύριες συνιστώσες και δουλέυουμε με τελείως νέες, γραμμικά ασυσχέτιστες μεταβλητές μικρότερης διαστατικότητας."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyVarThreshold(data,thres=0):\n",
    "    selector = VarianceThreshold(threshold=thres)\n",
    "    return selector.fit_transform(data)\n",
    "\n",
    "def applyPCA(data,num=len(data[0])):\n",
    "    pca = PCA(n_components=num)\n",
    "    return pca.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rUbXZ0iHtvnj"
   },
   "outputs": [],
   "source": [
    "def cross_validation(clf,x_cv,y_cv,cv):\n",
    "    \n",
    "    array = []\n",
    "    fold_len = len(x_cv)//cv\n",
    "    for fold_num in range(cv): array.append(fold_num*fold_len)\n",
    "    \n",
    "    test_acc  = []\n",
    "    for i in array:\n",
    "        x_test_temp  = x_cv[i:i+fold_len]\n",
    "        y_test_temp  = y_cv[i:i+fold_len]\n",
    "        x_train_temp = np.concatenate((x_cv[:i],x_cv[i+fold_len:]))\n",
    "        y_train_temp = np.concatenate((y_cv[:i],y_cv[i+fold_len:]))\n",
    "        clf.fit(x_train_temp,y_train_temp)\n",
    "        test_acc.append(clf.score(x_test_temp,y_test_temp))\n",
    "    \n",
    "    return test_acc\n",
    "\n",
    "\n",
    "def gridsearch(data,labels,scaler=False,var_thresh=False,pca=False):\n",
    "    \n",
    "    accuracies = {}\n",
    "    \n",
    "    if scaler == 'MinMax': \n",
    "        scaler = preprocessing.MinMaxScaler()\n",
    "        data   = scaler.fit_transform(data)\n",
    "    elif scaler == 'Standard': \n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        data   = scaler.fit_transform(data)\n",
    "    \n",
    "    for thres in np.arange(0,0.25,0.05):\n",
    "        data_var = data\n",
    "        if var_thresh: data_var = applyVarThreshold(data,thres)\n",
    "                \n",
    "        for i in range(1,len(data[0])):\n",
    "            data_pca = data_var\n",
    "            if pca: data_pca = applyPCA(data_var,i)\n",
    "\n",
    "            for j in range(1,len(data_pca)//2):\n",
    "                knn = KNeighborsClassifier(n_neighbors=j) \n",
    "                test_score = cross_validation(knn,data_pca,labels,10)\n",
    "                accuracies[str(i)+\"_\"+str(thres)+\"_\"+str(j)] = np.mean(test_score)\n",
    "\n",
    "            if not pca: break   \n",
    "        if not var_thresh: break \n",
    "    \n",
    "    k = max(accuracies,key=accuracies.get)\n",
    "    score = accuracies[k]\n",
    "    params = k.split(\"_\")\n",
    "    if var_thresh: print(\"Best Variance Threshold:\",params[1])\n",
    "    if pca: print(\"Best PCA Components Number:\",params[0])\n",
    "    print(\"Best k for k-NN:\",params[2])\n",
    "    print(\"Score:\",round(score,3))\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Αρχικά θα εξετάσουμε αν το scaling των δεδομένων θα αυξήσει το accuracy score του k-NN. Θα δοκιμάσουμε τόσο Standard όσο και MinMax scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Scaling:\n",
      "Best k for k-NN: 7\n",
      "Score: 0.692\n",
      "\n",
      "With Standard Scaling:\n",
      "Best k for k-NN: 10\n",
      "Score: 0.746\n",
      "\n",
      "With MinMax Scaling:\n",
      "Best k for k-NN: 7\n",
      "Score: 0.754\n"
     ]
    }
   ],
   "source": [
    "print(\"Without Scaling:\")\n",
    "optimal_params = gridsearch(x_train,y_train,scaler=False,var_thresh=False,pca=False)\n",
    "\n",
    "print(\"\\nWith Standard Scaling:\")\n",
    "optimal_params = gridsearch(x_train,y_train,scaler='Standard',var_thresh=False,pca=False)\n",
    "\n",
    "print(\"\\nWith MinMax Scaling:\")\n",
    "optimal_params = gridsearch(x_train,y_train,scaler='MinMax',var_thresh=False,pca=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Συνάγουμε ότι η χρήση scaling βελτιώνει ιδιαιτέρως την επίδοση του ταξινομητή. Από τους δύο scalers καλύτερος είναι ο MinMax ενώ αξίζει να αναφέρουμε ότι οι δύο scalers προτείνουν διαφορετικά βέλτιστα k. Στη συνέχεια, δεδομένου του MinMax scaling, εξετάζουμε την επίδραση του Variance Threshold.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Variance Threshold: 0.0\n",
      "Best k for k-NN: 7\n",
      "Score: 0.754\n"
     ]
    }
   ],
   "source": [
    "optimal_params = gridsearch(x_train,y_train,scaler='MinMax',var_thresh=True,pca=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Συνάγουμε πως το Variance Threshold δεν έχει καμία επίδραση στο τελικό αποτέλεσμα. Όλα τα στοιχεία (τυπικά πλην αυτών που δεν έχουν καμία διακύμανση και είναι άχρηστα) διατηρούνται και το ποσοστό παραμένει αυτό που λάβαμε και προηγουμένως για MinMax scaling. Θα εξετάσουμε τώρα την επίδραση του PCA decomposition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best PCA Components Number: 4\n",
      "Best k for k-NN: 5\n",
      "Score: 0.785\n"
     ]
    }
   ],
   "source": [
    "optimal_params = gridsearch(x_train,y_train,scaler='MinMax',var_thresh=False,pca=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "701zzsbDtvnr"
   },
   "source": [
    "Βλέπουμε πως το αποτέλεσμα βελτιώνεται περαιτέρω κατά 3% με την μείωση σε 4 διαστάσεις των δεδομένων μέσω PCA. Παρατηρούμε εδώ και μια αλλαγή στο βέλτιστο αριθμό των κοντινότερων γειτόνων. Τελικώς, από το grid search λαμβάνουμε τις εξής βέλτιστες υπερπαραμέτρους:\n",
    "* Scaling: **MinMax**\n",
    "* Variance Threshold: **0.0**\n",
    "* PCA Decomposition: **4 components**\n",
    "* Number of nearest neighbors: **5 neighbors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uYdb4lyPtvnv"
   },
   "source": [
    "Επαναλαμβάνουμε τώρα τη διαδικασία ταξινόμησης με τις βελτιστοποιημένες παραμέτρους. Θα κάνουμε νέο τρέξιμο μόνο τον ταξινομητή k-NN αφού οι dummy classifiers δεν επηρεάζονται από τις παραπάνω παραμέτρους. Θα παραθέσουμε πάντως και αυτούς, μαζί με το χρόνο που διαρκεί ο καθένας."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled  = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "9jjLqHGRtvnw",
    "outputId": "5c7cc067-0436-4006-bd98-f6c3fc96e941"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy of Dummy Classifiers for the test set:\n",
      "\n",
      "With uniform strategy: 42.424 %\n",
      "With const_0 strategy: 39.394 %\n",
      "With const_1 strategy: 60.606 %\n",
      "With stratif strategy: 69.697 %\n",
      "With frequent strategy: 60.606 %\n",
      "\n",
      "Confusion Matrices of Dummy Classifiers for the test set:\n",
      "\n",
      "With uniform strategy:\n",
      " [[ 8  5]\n",
      " [ 8 12]]\n",
      "With const_0 strategy:\n",
      " [[13  0]\n",
      " [20  0]]\n",
      "With const_1 strategy:\n",
      " [[ 0 13]\n",
      " [ 0 20]]\n",
      "With stratif strategy:\n",
      " [[ 6  7]\n",
      " [ 7 13]]\n",
      "With frequent strategy:\n",
      " [[ 0 13]\n",
      " [ 0 20]]\n",
      "\n",
      "Classification Report of uniform strategy:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.38      0.34        13\n",
      "           1       0.53      0.45      0.49        20\n",
      "\n",
      "    accuracy                           0.42        33\n",
      "   macro avg       0.42      0.42      0.42        33\n",
      "weighted avg       0.44      0.42      0.43        33\n",
      "\n",
      "\n",
      "Classification Report of const_0 strategy:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      1.00      0.57        13\n",
      "           1       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.39        33\n",
      "   macro avg       0.20      0.50      0.28        33\n",
      "weighted avg       0.16      0.39      0.22        33\n",
      "\n",
      "\n",
      "Classification Report of const_1 strategy:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.61      1.00      0.75        20\n",
      "\n",
      "    accuracy                           0.61        33\n",
      "   macro avg       0.30      0.50      0.38        33\n",
      "weighted avg       0.37      0.61      0.46        33\n",
      "\n",
      "\n",
      "Classification Report of stratif strategy:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.31      0.33        13\n",
      "           1       0.59      0.65      0.62        20\n",
      "\n",
      "    accuracy                           0.52        33\n",
      "   macro avg       0.48      0.48      0.48        33\n",
      "weighted avg       0.50      0.52      0.51        33\n",
      "\n",
      "\n",
      "Classification Report of frequent strategy:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.61      1.00      0.75        20\n",
      "\n",
      "    accuracy                           0.61        33\n",
      "   macro avg       0.30      0.50      0.38        33\n",
      "weighted avg       0.37      0.61      0.46        33\n",
      "\n",
      "\n",
      "Fit and Predict duration of Dummy Classifiers in secs:\n",
      "\n",
      "Fitting time for uniform strategy: 0.008278846740722656\n",
      "Predict time for uniform strategy: 0.00016641616821289062 \n",
      "\n",
      "Fitting time for const_0 strategy: 0.00027751922607421875\n",
      "Predict time for const_0 strategy: 6.937980651855469e-05 \n",
      "\n",
      "Fitting time for const_1 strategy: 0.0002205371856689453\n",
      "Predict time for const_1 strategy: 6.151199340820312e-05 \n",
      "\n",
      "Fitting time for stratif strategy: 0.00017642974853515625\n",
      "Predict time for stratif strategy: 0.0001811981201171875 \n",
      "\n",
      "Fitting time for frequent strategy: 0.00016736984252929688\n",
      "Predict time for frequent strategy: 7.200241088867188e-05 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "npredictions, nsmall_accuracies, fit_times, pred_times = DummyClassification(x_train_scaled,y_train,x_test_scaled,y_test)\n",
    "\n",
    "print(\"Classification Accuracy of Dummy Classifiers for the test set:\\n\")\n",
    "for strategy in nsmall_accuracies: print(\"With\",strategy,\"strategy:\",np.round(100*nsmall_accuracies[strategy],3),\"%\")\n",
    "\n",
    "print(\"\\nConfusion Matrices of Dummy Classifiers for the test set:\\n\")\n",
    "for strategy in npredictions: print(\"With\",strategy,\"strategy:\\n\",confusion_matrix(y_test,npredictions[strategy]))\n",
    "\n",
    "for strategy in predictions:\n",
    "    print(\"\\nClassification Report of\",strategy,\"strategy:\\n\",classification_report(y_test,predictions[strategy]))\n",
    "    \n",
    "print(\"\\nFit and Predict duration of Dummy Classifiers in secs:\\n\")\n",
    "for strategy in npredictions:\n",
    "    print(\"Fitting time for\",strategy,\"strategy:\",fit_times[strategy])\n",
    "    print(\"Predict time for\",strategy,\"strategy:\",pred_times[strategy],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy of k-NN for the test set: 57.576 %\n",
      "\n",
      "Confusion Matrix of k-NN for the test set:\n",
      " [[ 4  9]\n",
      " [ 5 15]]\n",
      "\n",
      "Classification Report of k-NN for the test set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.31      0.36        13\n",
      "           1       0.62      0.75      0.68        20\n",
      "\n",
      "    accuracy                           0.58        33\n",
      "   macro avg       0.53      0.53      0.52        33\n",
      "weighted avg       0.55      0.58      0.56        33\n",
      "\n",
      "\n",
      "Fitting time for k-NN Classifier: 0.001397848129272461\n",
      "Predict time for k-NN Classifier: 0.005410909652709961\n"
     ]
    }
   ],
   "source": [
    "x_train_scaled = applyPCA(x_train_scaled,int(optimal_params[0]))\n",
    "x_test_scaled  = applyPCA(x_test_scaled,int(optimal_params[0]))\n",
    "knn = KNeighborsClassifier(int(optimal_params[2]))\n",
    "\n",
    "start_time = time.time()\n",
    "knn.fit(x_train_scaled,y_train)\n",
    "fit_times['knn'] = time.time()-start_time\n",
    "\n",
    "start_time = time.time()\n",
    "npredictions['knn'] = knn.predict(x_test_scaled)\n",
    "pred_times['knn'] = time.time()-start_time\n",
    "\n",
    "nsmall_accuracies['knn'] = knn.score(x_test_scaled,y_test)\n",
    "\n",
    "print(\"Classification Accuracy of k-NN for the test set:\",np.round(100*nsmall_accuracies['knn'],3),\"%\")\n",
    "print(\"\\nConfusion Matrix of k-NN for the test set:\\n\",confusion_matrix(y_test,npredictions['knn']))\n",
    "print(\"\\nClassification Report of k-NN for the test set:\\n\",classification_report(y_test,npredictions['knn']))\n",
    "print(\"\\nFitting time for k-NN Classifier:\",fit_times['knn'])\n",
    "print(\"Predict time for k-NN Classifier:\",pred_times['knn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fuVmubGvtvn3"
   },
   "source": [
    "Παρατηρούμε πως η απόδοση χειροτερεύει εφαρμόζοντας τις παραμέτρους που βρήκαμε στο grid search. Αυτό μπορεί να οφείλεται αποκλειστικά στο μικρό μέγεθος του dataset. Τα δεδομένα μας δεν είναι αρκετά αντιπροσωπευτικά, ώστε να διατηρούν ίδιες ιδιότητες κατά το split σε train, validation και test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TkzuhixStvn4"
   },
   "source": [
    "#### 3. Bar Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "colab_type": "code",
    "id": "qrgKQ23Ztvn5",
    "outputId": "a63d1b18-a970-4f9c-af30-f1fb447d6dc5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1_macros, f1_micros, labels = [],[],[]\n",
    "for clf in npredictions:  \n",
    "    f1_micros.append(f1_score(y_test,npredictions[clf],average='micro'))\n",
    "    f1_macros.append(f1_score(y_test,npredictions[clf],average='macro'))\n",
    "    labels.append(clf)\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, f1_micros, width, label='f1_micros')\n",
    "rects2 = ax.bar(x + width/2, f1_macros, width, label='f1_macros')\n",
    "\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Performance Comparison on F1-Score')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CiM4KYIntvn8"
   },
   "source": [
    "#### 4. Optimization Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "xIfo_0tdtvn8",
    "outputId": "e00bfd6f-6b5e-448d-894c-d1d82b7de416"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement for uniform : 0.0\n",
      "Improvement for const_0 : 0.0\n",
      "Improvement for const_1 : 0.0\n",
      "Improvement for stratif : -0.061\n",
      "Improvement for frequent : 0.0\n",
      "Improvement for knn : -0.091\n"
     ]
    }
   ],
   "source": [
    "nsmall_accuracies['knn']=nsmall_accuracies['knn']\n",
    "for clf in small_accuracies:\n",
    "    print(\"Improvement for\",clf,\":\",np.round(nsmall_accuracies[clf]-small_accuracies[clf],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YrQuzM3Etvn_"
   },
   "source": [
    "#### 5. Discussion\n",
    "\n",
    "Όπως περιγράψαμε παραπάνω, ακολουθήσαμε μια bottom-up λογική για να επιλέξουμε τις βέλτιστες υπερπαραμέτρους pre-processing και training του dataset, ούτως ώστε να αυξήσουμε το accuracy της ταξινόμησης. Ενώ είδαμε βελτίωση με τη μέθοδο του cross validation, η μη αντιπροσωπευτικότητα των επιμέρους sets δεν επέτρεψε την αύξηση του score στο test set, το αντίθετο μάλιστα. Από κει και πέρα, οι παρατηρήσεις που έγιναν στο (C) για τους dummy classifiers συνεχίζουν να ισχύουν καθώς αυτοί δεν επηρεάζονται από το tuning. Όσον αφορά τους χρόνους εκτέλεσης, αξίζει να παρατηρήσουμε ότι το fit παίρνει περισσότερο χρόνο από το prediction. Τα παραπάνω συμπεράσματα φαίνονται και στο Optimization Table παραπάνω."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "MB4-S05(ntinos).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
