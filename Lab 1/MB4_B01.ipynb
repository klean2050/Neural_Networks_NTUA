{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SmPwXg_ftpDl"
   },
   "source": [
    "# Neural Networks ECE NTUA Course 2019-20 ~ Team M.B.4\n",
    "## Lab Assingment #1: Classification - Study of UCI Datasets - Big (B01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jC5zkEAdtpDp"
   },
   "source": [
    "### A. The Team\n",
    "* Αβραμίδης Κλεάνθης   ~ 03115117\n",
    "* Κρατημένος Άγγελος   ~ 03115025\n",
    "* Πανίδης Κωνσταντίνος ~ 03113602\n",
    "\n",
    "*Σημείωση: Θεωρούμε γνωστό και δεδομένο το small notebook, συνεπώς δε θα επαναληφθούν αναλυτικά προαναφερθείσες έννοιες.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cxqccrLDtpDq"
   },
   "source": [
    "### B. The Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kZMaqnMItpDr"
   },
   "source": [
    "#### 1. Introduction\n",
    "\n",
    "Παραθέτουμε την επίσημη περιγραφή που παρέχει το dataset:\n",
    "\n",
    "The data are MC generated to simulate registration of high energy\n",
    "   gamma particles in a ground-based atmospheric Cherenkov gamma telescope using the\n",
    "   imaging technique. Cherenkov gamma telescope observes high energy gamma rays,\n",
    "   taking advantage of the radiation emitted by charged particles produced\n",
    "   inside the electromagnetic showers initiated by the gammas, and developing in the\n",
    "   atmosphere. This Cherenkov radiation leaks\n",
    "   through the atmosphere and gets recorded in the detector, allowing reconstruction\n",
    "   of the shower parameters. The available information consists of pulses left by\n",
    "   the incoming Cherenkov photons on the photomultiplier tubes, arranged in a\n",
    "   plane, the camera. Depending on the energy of the primary gamma, a total of\n",
    "   few hundreds to some 10000 Cherenkov photons get collected in patterns,\n",
    "   allowing to discriminate statistically those\n",
    "   caused by primary gammas from the images of hadronic showers\n",
    "   initiated by cosmic rays in the upper atmosphere. Typically, the image of a shower after some pre-processing is an elongated\n",
    "   cluster. Its long axis is oriented towards the camera center if the shower axis\n",
    "   is parallel to the telescope's optical axis, i.e. if the telescope axis is\n",
    "   directed towards a point source. A principal component analysis is performed\n",
    "   in the camera plane, which results in a correlation axis and defines an ellipse.\n",
    "   The energy depositions are typically asymmetric\n",
    "   along the major axis, and this asymmetry can also be used in discrimination.\n",
    "   There are, in addition, further discriminating characteristics, like the\n",
    "   extent of the cluster in the image plane, or the total sum of depositions.\n",
    "\n",
    "Τα δεδομένα δημιουργήθηκαν από ένα Monte Carlo πρόγραμμα, Corsika, και περιγράφεται από το \n",
    "      *D. Heck et al., CORSIKA, A Monte Carlo code to simulate extensive air showers,\n",
    "      Forschungszentrum Karlsruhe FZKA 6019 (1998).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vWqtyRYWtpDt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, time\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support,f1_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l2_KDCnNtpDs"
   },
   "source": [
    "#### 2. Samples & Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "J2C5n1X9tpDy",
    "outputId": "302c8228-39cd-42d5-febf-c77dd4375232"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dataset contains 19020 samples, 10 features and a label.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"magic04.data\",header=None).to_numpy()\n",
    "print(\"The Dataset contains\",data.shape[0],\"samples,\",data.shape[1]-1,\"features and a label.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xGa9gX0FtpD2"
   },
   "source": [
    "Προκύπτει ότι το Dataset αποτελείται από 19020 δείγματα, καθένα εκ των οποίων έχει 10 χαρακτηριστικά συν την binary ετικέτα του. Στη συνέχεια θα εξετάσουμε το είδος των χαρακτηριστικών μέσω του δείγματος μιας και το dataset δεν έχει απουσιάζουσες τιμές."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "nmTslYkotpD3",
    "outputId": "571dc9ad-54b2-4937-b93f-aece1607bf08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of features: {<class 'str'>, <class 'float'>}\n",
      "Inspection of features: [28.7967 16.0021 2.6449 0.3918 0.1982 27.7004 22.011 -8.2027 40.092\n",
      " 81.8828 'g']\n"
     ]
    }
   ],
   "source": [
    "print(\"Data types of features:\",set([type(feature) for feature in data[0]]))\n",
    "print(\"Inspection of features:\",data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k3A2ZZfUtpD6"
   },
   "source": [
    "Παρατηρούμε πως όλα τα χαρακτηριστικά λαμβάνουν αριθμητικές float τιμές και η μόνη μη διατεταγμένη μορφή είναι η τελευταία στήλη που υποδηλώνει το label και είναι τύπου str."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8cm4XarktpD7"
   },
   "source": [
    "#### 4. Labels\n",
    "\n",
    "Σύμφωνα με το documentation, οι ετικέτες των δειγμάτων λαμβάνουν τις τιμές g (gamma) ή h (hadron) και βρίσκονται στην τελευταία κολόνα του ```data```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qnj5i0EEtpD8",
    "outputId": "0f1b4a01-09d2-498b-de55-f4ef93d415ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels of the Dataset: {'h', 'g'}\n"
     ]
    }
   ],
   "source": [
    "labels = data[:,-1]\n",
    "feats  = data[:,:-1]\n",
    "print(\"Labels of the Dataset:\",set(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7wxdSr_tpD_"
   },
   "source": [
    "#### 5. Pre-Processing\n",
    "\n",
    "Δεν απαιτήθηκε κάποια προσαρμογή των input files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GFzalV2NtpEA"
   },
   "source": [
    "#### 6. Missing Values\n",
    "\n",
    "Δεν υπάρχουν απουσιάζουσες τιμές σύμφωνα με το documentation του dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n0G4-5XdtpEB"
   },
   "source": [
    "#### 7. Balance\n",
    "\n",
    "Λόγω της binary φύσης των labels, μπορούμε να εκτιμήσουμε απευθείας πόσα στοιχεία ανήκουν σε κάθε κλάση μέσω της συνάρτησης sum(), άρα και να αποφανθούμε περί της ισορροπίας του Dataset, διαιρώντας με τον συνολικό αριθμό των δειγμάτων:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "FZsepNSqtpEC",
    "outputId": "8f7510fe-d27d-4344-de4e-b272df9b3a36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19020, 10)\n",
      "12332 samples are gamma and 6688 are hadron\n",
      "The balance of the Dataset is 0.65 in favor of the gamma samples.\n"
     ]
    }
   ],
   "source": [
    "np_labels = np.array(labels)\n",
    "print(feats.shape)\n",
    "print(len(np_labels[np_labels=='g']),\"samples are gamma and\",len(np_labels)-len(np_labels[np_labels=='g']),\"are hadron\")\n",
    "print(\"The balance of the Dataset is\",round(len(np_labels[np_labels=='g'])/len(labels),2),\"in favor of the gamma samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KOD94SQitpEF"
   },
   "source": [
    "Είναι εμφανές πως τα δεδομένα κλίνουν κατά ένα βαθμό στην κλάση gamma, συνεπώς τα δεδομένα μας δεν είναι καλώς ισορροπημένα. Παρότι το ποσοστό παραμένει οριακά μικρότερο από 2/3 και θα μπορούσαμε να μην κάνουμε κάτι επιπλέον, επιλέγουμε να εφαρμόσουμε oversampling, θεωρώντας ότι όσο πιο ισορροπημένο είναι το dataset, τόσο καλύτερα θα είναι τα αποτελέσματα. Για να γίνει αυτό θα προηγηθεί το split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W_Zu-Is_tpEG"
   },
   "source": [
    "#### 8. Train & Test Set\n",
    "\n",
    "Σαν τελευταίο βήμα επεξεργασίας, θα χωρίσουμε τα δεδομένα σε train και test μέσω της αντίστοιχης συνάρτησης *train_test_split()* της Scikit-learn. Αντίστοιχα χωρίζουμε και τα labels. Επιλέγουμε σχήμα 20% για το test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kq_4PeoUtpEH"
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(feats,labels,test_size=0.3,random_state=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F2O6eNBbtpEK"
   },
   "source": [
    "Ως τελευταίο βήμα, θα εφαρμόσουμε oversampling ούτως ώστε να εξισορροπήσουμε το dataset, όπως προείπαμε. Η έννοια του oversampling ειναι πρακτικά η επανάληψη samples από την υπολείπουσα κλάση, ώστε ο λόγος τους να τείνει προς το ιδανικό 50%. Θα εφαρμόσουμε για αυτό το σκοπό την συνάρτηση της Scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XbUvHJALtpEL",
    "outputId": "f9cbcbd5-e7d3-4aaf-ebfe-7391c28b2b88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The balance of the train set is 0.5\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state = 0)\n",
    "x_train, y_train = ros.fit_sample(x_train,y_train)\n",
    "balance = len(y_train[y_train=='g'])/len(y_train)\n",
    "\n",
    "print(\"The balance of the train set is\",balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZyPBOtlUtpEO"
   },
   "source": [
    "Παρατηρούμε την απευθείας βελτίωση στο λόγο των 2 κλάσεων. Σημειώνουμε πως επιλέγουμε να ισορροπήσουμε μόνο τα δεδομένα εκπαίδευσης, τα οποία είναι και τα μόνα που οφείλουν να είναι ισορροπημένα. Γενικώς αποφεύγουμε οποιαδήποτε περαιτέρω επεξεργασία στα test δεδομένα."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkTU-8-VtpEP"
   },
   "source": [
    "### C. Baseline Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "COQY2igStpEQ"
   },
   "source": [
    "#### 1. Classification & Metrics\n",
    "\n",
    "Ορίζουμε μία συνάρτηση που εκπαιδεύει τους dummy classifiers με default τιμές και επιστρέφει σε dictionary τα predictions κάθε ταξινομητή, την ακρίβεια του καθώς και τους χρόνους fit και train \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QLZvloaItpEU"
   },
   "outputs": [],
   "source": [
    "def DummyClassification(x_train,y_train,x_test,y_test):\n",
    "    \n",
    "    scores, predictions, fit_times, pred_times = {}, {}, {}, {}\n",
    "\n",
    "    ### Initialization ###\n",
    "    \n",
    "    dc_uniform  = DummyClassifier(strategy=\"uniform\")\n",
    "    dc_const_0  = DummyClassifier(strategy=\"constant\",constant='g')\n",
    "    dc_const_1  = DummyClassifier(strategy=\"constant\",constant='h')\n",
    "    dc_stratif  = DummyClassifier(strategy=\"stratified\")\n",
    "    dc_frequent = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "    ### Fit ###\n",
    "    \n",
    "    start_time = time.time()\n",
    "    dc_uniform.fit(x_train, y_train)\n",
    "    fit_times['uniform'] = time.time()-start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    dc_const_0.fit(x_train, y_train)\n",
    "    fit_times['const_0'] = time.time()-start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    dc_const_1.fit(x_train, y_train)\n",
    "    fit_times['const_1'] = time.time()-start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    dc_stratif.fit(x_train, y_train)\n",
    "    fit_times['stratif'] = time.time()-start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    dc_frequent.fit(x_train,y_train)\n",
    "    fit_times['frequent'] = time.time()-start_time\n",
    "    \n",
    "    ### Predict ###\n",
    "    \n",
    "    start_time = time.time()\n",
    "    predictions['uniform']  = dc_uniform.predict(x_test)\n",
    "    pred_times['uniform'] = time.time()-start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    predictions['const_0']  = dc_const_0.predict(x_test)\n",
    "    pred_times['const_0'] = time.time()-start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    predictions['const_1']  = dc_const_1.predict(x_test)\n",
    "    pred_times['const_1'] = time.time()-start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    predictions['stratif']  = dc_stratif.predict(x_test)\n",
    "    pred_times['stratif'] = time.time()-start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    predictions['frequent'] = dc_frequent.predict(x_test)\n",
    "    pred_times['frequent'] = time.time()-start_time\n",
    "\n",
    "    ### Score ###\n",
    "    \n",
    "    scores['uniform']  = dc_uniform.score(x_test, y_test)\n",
    "    scores['const_0']  = dc_const_0.score(x_test, y_test)\n",
    "    scores['const_1']  = dc_const_1.score(x_test, y_test)\n",
    "    scores['stratif']  = dc_stratif.score(x_test, y_test)\n",
    "    scores['frequent'] = dc_frequent.score(x_test,y_test)\n",
    "    \n",
    "    return predictions, scores, fit_times, pred_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "V8HBx0nKtpEX",
    "outputId": "96b7692f-e522-41cc-b884-bae76b31dcaa",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy of Dummy Classifiers for the test set:\n",
      "\n",
      "With uniform strategy: 48.931 %\n",
      "With const_0 strategy: 64.651 %\n",
      "With const_1 strategy: 35.349 %\n",
      "With stratif strategy: 49.334 %\n",
      "With frequent strategy: 64.651 %\n",
      "\n",
      "Confusion Matrices of Dummy Classifiers for the test set:\n",
      "\n",
      "With uniform strategy:\n",
      " [[1867 1822]\n",
      " [ 961 1056]]\n",
      "With const_0 strategy:\n",
      " [[3689    0]\n",
      " [2017    0]]\n",
      "With const_1 strategy:\n",
      " [[   0 3689]\n",
      " [   0 2017]]\n",
      "With stratif strategy:\n",
      " [[1850 1839]\n",
      " [1005 1012]]\n",
      "With frequent strategy:\n",
      " [[3689    0]\n",
      " [2017    0]]\n",
      "\n",
      "f1-micro average of uniform strategy: 0.5122677882930249\n",
      "f1-macro average of uniform strategy: 0.5022118469758436\n",
      "\n",
      "f1-micro average of const_0 strategy: 0.6465124430424115\n",
      "f1-macro average of const_0 strategy: 0.3926556679084619\n",
      "\n",
      "f1-micro average of const_1 strategy: 0.3534875569575885\n",
      "f1-macro average of const_1 strategy: 0.2611679399197203\n",
      "\n",
      "f1-micro average of stratif strategy: 0.501577287066246\n",
      "f1-macro average of stratif strategy: 0.4905899612860194\n",
      "\n",
      "f1-micro average of frequent strategy: 0.6465124430424115\n",
      "f1-macro average of frequent strategy: 0.3926556679084619\n"
     ]
    }
   ],
   "source": [
    "predictions, big_accuracies, _, _ = DummyClassification(x_train,y_train,x_test,y_test)\n",
    "\n",
    "print(\"Classification Accuracy of Dummy Classifiers for the test set:\\n\")\n",
    "for strategy in big_accuracies: print(\"With\",strategy,\"strategy:\",np.round(100*big_accuracies[strategy],3),\"%\")\n",
    "\n",
    "print(\"\\nConfusion Matrices of Dummy Classifiers for the test set:\\n\")\n",
    "for strategy in predictions: print(\"With\",strategy,\"strategy:\\n\",confusion_matrix(y_test,predictions[strategy]))\n",
    "\n",
    "for strategy in predictions:\n",
    "    print(\"\\nf1-micro average of\",strategy,\"strategy:\",f1_score(y_test,predictions[strategy], average='micro'))\n",
    "    print(\"f1-macro average of\",strategy,\"strategy:\",f1_score(y_test,predictions[strategy], average='macro'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "buFKwLqftpEa"
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train,y_train)\n",
    "predictions['gnb'] = gnb.predict(x_test)\n",
    "big_accuracies['gnb'] = gnb.score(x_test,y_test)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1) \n",
    "knn.fit(x_train,y_train)\n",
    "predictions['knn'] = knn.predict(x_test)\n",
    "big_accuracies['knn'] = knn.score(x_test,y_test)\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(10,2),random_state=1,max_iter=1000) \n",
    "mlp.fit(x_train,y_train)\n",
    "predictions['mlp'] = mlp.predict(x_test)\n",
    "big_accuracies['mlp'] = mlp.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "vRTp1wuttpEd",
    "outputId": "690779cb-471c-491a-ec38-5f442cc6c340"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy of GNB for the test set: 72.205 %\n",
      "\n",
      "Confusion Matrix of GNB for the test set:\n",
      " [[3317  372]\n",
      " [1214  803]]\n",
      "\n",
      "f1-micro average of GNB Classifier: 0.7220469681037505\n",
      "f1-macro average of GNB Classifier: 0.6550943965753802\n",
      "\n",
      "\n",
      "Classification Accuracy of 1-NN for the test set: 77.83 %\n",
      "\n",
      "Confusion Matrix of 1-NN for the test set:\n",
      " [[3189  500]\n",
      " [ 765 1252]]\n",
      "\n",
      "f1-micro average of 1-NN Classifier: 0.778303540133193\n",
      "f1-macro average of 1-NN Classifier: 0.7494281405630201\n",
      "\n",
      "\n",
      "Classification Accuracy of MLP for the test set: 66.158 %\n",
      "\n",
      "Confusion Matrix of MLP for the test set:\n",
      " [[3682    7]\n",
      " [1924   93]]\n",
      "\n",
      "f1-micro average of MLP Classifier: 0.6615842972309849\n",
      "f1-macro average of MLP Classifier: 0.4400570397227495\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Accuracy of GNB for the test set:\",np.round(100*big_accuracies['gnb'],3),\"%\")\n",
    "print(\"\\nConfusion Matrix of GNB for the test set:\\n\",confusion_matrix(y_test,predictions['gnb']))\n",
    "print(\"\\nf1-micro average of GNB Classifier:\",f1_score(y_test,predictions['gnb'], average='micro'))\n",
    "print(\"f1-macro average of GNB Classifier:\",f1_score(y_test,predictions['gnb'], average='macro'))\n",
    "print();print()\n",
    "\n",
    "print(\"Classification Accuracy of 1-NN for the test set:\",np.round(100*big_accuracies['knn'],3),\"%\")\n",
    "print(\"\\nConfusion Matrix of 1-NN for the test set:\\n\",confusion_matrix(y_test,predictions['knn']))\n",
    "print(\"\\nf1-micro average of 1-NN Classifier:\",f1_score(y_test,predictions['knn'], average='micro'))\n",
    "print(\"f1-macro average of 1-NN Classifier:\",f1_score(y_test,predictions['knn'], average='macro'))\n",
    "print();print()\n",
    "\n",
    "print(\"Classification Accuracy of MLP for the test set:\",np.round(100*big_accuracies['mlp'],3),\"%\")\n",
    "print(\"\\nConfusion Matrix of MLP for the test set:\\n\",confusion_matrix(y_test,predictions['mlp']))\n",
    "print(\"\\nf1-micro average of MLP Classifier:\",f1_score(y_test,predictions['mlp'], average='micro'))\n",
    "print(\"f1-macro average of MLP Classifier:\",f1_score(y_test,predictions['mlp'], average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hNp4c3ystpEg"
   },
   "source": [
    "#### 2. Bar Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "HMdoWR57tpEh",
    "outputId": "73de085a-a6b2-44d2-9cad-aa6b79a2ef34"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1_macros, f1_micros, labels = [],[],[]\n",
    "for clf in predictions:  \n",
    "    f1_micros.append(f1_score(y_test,predictions[clf],average='micro'))\n",
    "    f1_macros.append(f1_score(y_test,predictions[clf],average='macro'))\n",
    "    labels.append(clf)\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, f1_micros, width, label='f1_micros')\n",
    "rects2 = ax.bar(x + width/2, f1_macros, width, label='f1_macros')\n",
    "\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Performance Comparison on F1-Score')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-5JytgYBtpEk"
   },
   "source": [
    "#### 3. Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "X4FNzNBjtpEl",
    "outputId": "48043d12-435e-44de-e0dc-2ac095560f8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The balance of the test set is 64.651 in favor of class 'g'.\n"
     ]
    }
   ],
   "source": [
    "print(\"The balance of the test set is\",round(100*len(y_test[y_test=='g'])/len(y_test),3),\"in favor of class 'g'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Μεταξύ των dummy ταξινομητών, η καλύτερη στρατηγική είναι να διαλέγουμε πάντοτε την πιο συχνή κλάση (frequent) ή ισοδύναμα σταθερά την κλάση που είναι η πιο συχνή (constant-0), μιας και το test set δεν είναι ισορροπημένο, όπως φαίνεται παραπάνω.\n",
    "* Εαν δοκιμάσουμε πολλά runs, θα παρατηρήσουμε ότι η επιλογή stratified, δηλαδή να επιλέγουμε τυχαία κλάση διατηρώντας την κατανομή των κλάσεων στο training set, ενώ στη γενική περίπτωση δίνει καλύτερα αποτελέσματα από τη random επιλογή, στη προκειμένη, λόγω της ισορροπίας του train dataset, οι δύο μέθοδοι είναι ισοδύναμες. \n",
    "* Ο k-NN ταξινομητής δίνει καλύτερο αποτέλεσμα από τους dummy classifiers, αφού βασίζεται σε έναν αλγόριθμο λογικής ανάλυσης των δεδομένων. Επιπλέον λόγω του εκτενούς μεγέθους του test dataset, το αποτέλεσμα του ταξινομητή είναι ικανοποιητικό.\n",
    "* Ο Naive Bayes εμφανίζει επίσης βελτιωμένα αποτελέσματα συγκριτικά με τους dummy ταξινομητές, αλλά όχι καλύτερα από τον kNN. Αυτό οφείλεται στις \"αφελείς\" παραδοχές του συγκεκριμένου ταξινομήτη, όπως το ότι υποθέτει κανονική κατανομή των features και ανεξαρτησία μεταξύ τους.\n",
    "* Τέλος, ο MLP εμφανίζει την χαμηλότερη επίδοση από τους non-Dummy ταξινομητές. Ο συγκεκριμένος ταξινομητής λαμβάνει πληθώρα παραμέτρων, η βελτιστοποίηση των οποίων θα οδηγήσει σε πιο ικανοποιητικό αποτέλεσμα. Επομένως, λόγω της επιλογής απλοϊκού συνδυασμού παραμέτρων, το ποσοστό είναι μέτριο αλλά παραμένει υψηλότερο από τους Dummy ταξινομητές."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TucfBYivtpEq"
   },
   "source": [
    "### D. Optimization of Classifiers\n",
    "\n",
    "Θα ακολουθήσουμε bottom-up λογική όπως στο small notebook. Για την εύρεση των βέλτιστων υπερπαραμέτρων θα διαχωρίσουμε το dataset σε 70% train και 30% test και θα χρησιμοποιήσουμε 5-fold cross validation για να εκτιμήσουμε τις παραμέτρους μόνο από το train set. Συγκεκριμένα, αφού γίνει η απαραίτητη προεπεξεργασία ολόκληρου του set, αυτό θα χωριστεί σε 5 subsets, καθένα από τα οποία θα δοκιμαστεί σαν validation set. Στη συνέχεια, οι παράμετροι θα δώσουν το καλύτερο cross score θα εφαρμοστούν προκειμένου να κάνουμε το τελικό prediction για το αρχικό μας test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FcQLlOJatpEs"
   },
   "source": [
    "#### 1-2. Pre-Processing - Optimization and Execution Time\n",
    "\n",
    "Για αρχή θα τρέξουμε πάλι τους dummy classifiers καθώς και τον Gaussian Naive Bayes, οι οποίοι δεν επηρεάζονται από το processing που θα ακολουθήσουμε. Αυτή τη φορά θα κάνουμε και track των χρόνων για fit και predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "TAuaN-8ktpE9",
    "outputId": "62a40a4d-4a6e-483f-f4a9-0a25fa0bc5f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy of Dummy Classifiers for the test set:\n",
      "\n",
      "With uniform strategy: 50.123 %\n",
      "With const_0 strategy: 64.651 %\n",
      "With const_1 strategy: 35.349 %\n",
      "With stratif strategy: 50.368 %\n",
      "With frequent strategy: 64.651 %\n",
      "With gnb strategy: 72.205 %\n",
      "\n",
      "Confusion Matrices of Dummy Classifiers for the test set:\n",
      "\n",
      "With uniform strategy:\n",
      " [[1853 1836]\n",
      " [1009 1008]]\n",
      "With const_0 strategy:\n",
      " [[3689    0]\n",
      " [2017    0]]\n",
      "With const_1 strategy:\n",
      " [[   0 3689]\n",
      " [   0 2017]]\n",
      "With stratif strategy:\n",
      " [[1820 1869]\n",
      " [1016 1001]]\n",
      "With frequent strategy:\n",
      " [[3689    0]\n",
      " [2017    0]]\n",
      "With gnb strategy:\n",
      " [[3317  372]\n",
      " [1214  803]]\n",
      "\n",
      "f1-micro average of uniform strategy: 0.5014020329477743\n",
      "f1-macro average of uniform strategy: 0.4902223187610536\n",
      "\n",
      "f1-micro average of const_0 strategy: 0.6465124430424115\n",
      "f1-macro average of const_0 strategy: 0.3926556679084619\n",
      "\n",
      "f1-micro average of const_1 strategy: 0.3534875569575885\n",
      "f1-macro average of const_1 strategy: 0.2611679399197203\n",
      "\n",
      "f1-micro average of stratif strategy: 0.4943918682089029\n",
      "f1-macro average of stratif strategy: 0.48375634159593006\n",
      "\n",
      "f1-micro average of frequent strategy: 0.6465124430424115\n",
      "f1-macro average of frequent strategy: 0.3926556679084619\n",
      "\n",
      "f1-micro average of gnb strategy: 0.7220469681037505\n",
      "f1-macro average of gnb strategy: 0.6550943965753802\n",
      "\n",
      "Fit and Predict duration of Dummy Classifiers in secs:\n",
      "\n",
      "Fitting time for uniform strategy: 0.0199737548828125\n",
      "Predict time for uniform strategy: 0.002454996109008789 \n",
      "\n",
      "Fitting time for const_0 strategy: 0.019029855728149414\n",
      "Predict time for const_0 strategy: 0.0004839897155761719 \n",
      "\n",
      "Fitting time for const_1 strategy: 0.020609140396118164\n",
      "Predict time for const_1 strategy: 0.0003237724304199219 \n",
      "\n",
      "Fitting time for stratif strategy: 0.024369478225708008\n",
      "Predict time for stratif strategy: 0.0014219284057617188 \n",
      "\n",
      "Fitting time for frequent strategy: 0.025705337524414062\n",
      "Predict time for frequent strategy: 0.0003802776336669922 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "npredictions, nbig_accuracies, fit_times, pred_times = DummyClassification(x_train,y_train,x_test,y_test)\n",
    "\n",
    "npredictions['gnb'] = predictions['gnb']\n",
    "nbig_accuracies['gnb'] = big_accuracies['gnb']\n",
    "\n",
    "print(\"Classification Accuracy of Dummy Classifiers for the test set:\\n\")\n",
    "for strategy in nbig_accuracies: print(\"With\",strategy,\"strategy:\",np.round(100*nbig_accuracies[strategy],3),\"%\")\n",
    "\n",
    "print(\"\\nConfusion Matrices of Dummy Classifiers for the test set:\\n\")\n",
    "for strategy in npredictions: print(\"With\",strategy,\"strategy:\\n\",confusion_matrix(y_test,npredictions[strategy]))\n",
    "\n",
    "for strategy in npredictions:\n",
    "    print(\"\\nf1-micro average of\",strategy,\"strategy:\",f1_score(y_test,npredictions[strategy], average='micro'))\n",
    "    print(\"f1-macro average of\",strategy,\"strategy:\",f1_score(y_test,npredictions[strategy], average='macro'))\n",
    "    \n",
    "print(\"\\nFit and Predict duration of Dummy Classifiers in secs:\\n\")\n",
    "for strategy in fit_times:\n",
    "    print(\"Fitting time for\",strategy,\"strategy:\",fit_times[strategy])\n",
    "    print(\"Predict time for\",strategy,\"strategy:\",pred_times[strategy],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Βλέπουμε, όπως και στο small notebook πως το fitting διαρκεί πολύ περισσότερο από το prediction. Ορίζουμε τώρα μία συνάρτηση που θα χρησιμοποιήσουμε, όπως και στο small για την εκτέλεση του PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p6bJtBPw5iRz"
   },
   "outputs": [],
   "source": [
    "def applyPCA(data,num=len(data[0])):\n",
    "    pca = PCA(n_components=num)\n",
    "    return pca.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Αρχικοποιούμε τους εκτιμητές χωρίς παραμέτρους:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OrwlvcgjtpE0"
   },
   "outputs": [],
   "source": [
    "selector = VarianceThreshold() # by default removes zero variance elements\n",
    "m_scaler = MinMaxScaler()\n",
    "pca = PCA()\n",
    "clf = KNeighborsClassifier(n_jobs=-1) # uses all available cores\n",
    "mlp = MLPClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AD0Lli4Un5yU"
   },
   "source": [
    "Η διαδικασία εύρεσης των βέλτιστων υπερπαραμέτρων είναι εκ γενετής μια χρονοβόρα και επαναληπτική διαδικασία πειραματισμών. Για αυτό το λόγο θα εκμεταλλευτούμε το μεγάλο μέγεθος του dataset και θα χρησιμοποιήσουμε μόνο ένα υποσύνολο των διαθέσιμων δειγμάτων, μέσω sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "8z_T-srzn4xK",
    "outputId": "048a10b4-792b-4823-96a4-ab4e363b78da"
   },
   "outputs": [],
   "source": [
    "x_train_copy = x_train\n",
    "y_train_copy = y_train\n",
    "x_test_copy  = x_test\n",
    "y_test_copy  = y_test\n",
    "\n",
    "x_train_sample, y_train_sample = shuffle(x_train, y_train, random_state=3)\n",
    "x_train_sample = x_train_sample[0:2000,:]\n",
    "y_train_sample = y_train_sample[0:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4c-0GPgUss1M"
   },
   "source": [
    "Μπορούμε τώρα να προσχωρήσουμε στην εύρεση των βέλτιστων παραμέτρων των μοντέλων μας. Θα εξετάσουμε χωριστά τις παραμέτρους των ταξινομητών MLP και k-NN καθώς ο Gaussian Naive Bayes δε διαθέτει παραμέτρους προς βελτιστοποίηση. Επίσης, επιλέγουμε να μην κάνουμε feature selection καθώς ο αριθμός των features είναι ήδη αρκετά μικρός σε σύγκριση με την ποσότητα των δεδομένων. Ξεκινάμε με τον k-NN classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "kIripiFdtpE2",
    "outputId": "a76db496-e922-47d3-ce03-d828e5689925"
   },
   "outputs": [],
   "source": [
    "n_components = np.arange(1,11)\n",
    "k = np.arange(1,50,5)\n",
    "knn_weights = ['uniform','distance']\n",
    "knn_metrics = ['euclidean','manhattan','chebyshev']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vkOLARYeskW0"
   },
   "source": [
    "Μπορούμε πλέον να στήσουμε το Pipeline για το classification των δεδομένων μας. Θα επιλέξουμε MinMax scaler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dr8tTO-GiSc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 600 candidates, totalling 3000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   45.5s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3000 out of 3000 | elapsed:  8.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Συνολικός χρόνος fit και predict: 499.81396865844727 seconds\n",
      "Best parameters {'kNN__metric': 'manhattan', 'kNN__n_neighbors': 6, 'kNN__weights': 'distance', 'pca__n_components': 10}\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[('scaler', m_scaler),('selector', selector),('pca', pca),('kNN', clf)], memory = 'tmp')\n",
    "estimator_knn = GridSearchCV(pipe, dict(pca__n_components = n_components,\n",
    "                                        kNN__n_neighbors = k,\n",
    "                                        kNN__weights = knn_weights,\n",
    "                                        kNN__metric = knn_metrics), cv=5, scoring='f1_macro', n_jobs=-1,verbose=1)\n",
    "\n",
    "start_time = time.time()\n",
    "estimator_knn.fit(x_train_sample,y_train_sample)\n",
    "preds = estimator_knn.predict(x_test)\n",
    "print(\"Συνολικός χρόνος fit και predict: %s seconds\" % (time.time()-start_time))\n",
    "print(\"Best parameters\",estimator_knn.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Έχοντας εξάγει παραμέτρους για ένα μικρό δείγμα του train set, επαναλαμβάνουμε την διαδικασία για όλο το dataset με πολύ μικρότερο εύρος παραμέτρων:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = np.arange(9,11)\n",
    "k = np.arange(3,9)\n",
    "knn_weights = ['distance']\n",
    "knn_metrics = ['manhattan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Συνολικός χρόνος fit και predict: 82.72279739379883 seconds\n",
      "Best parameters {'kNN__metric': 'manhattan', 'kNN__n_neighbors': 8, 'kNN__weights': 'distance', 'pca__n_components': 10}\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[('scaler', m_scaler),('selector', selector),('pca', pca),('kNN', clf)], memory = 'tmp')\n",
    "estimator_knn = GridSearchCV(pipe, dict(pca__n_components = n_components,\n",
    "                                        kNN__n_neighbors = k,\n",
    "                                        kNN__weights = knn_weights,\n",
    "                                        kNN__metric = knn_metrics), cv=5, scoring='f1_macro', n_jobs=-1,verbose=1)\n",
    "\n",
    "start_time = time.time()\n",
    "estimator_knn.fit(x_train,y_train)\n",
    "print(\"Συνολικός χρόνος fit και predict: %s seconds\" % (time.time()-start_time))\n",
    "print(\"Best parameters\",estimator_knn.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7tBPKhtyzupw"
   },
   "source": [
    "Εφαρμόζουμε τώρα τις βέλτιστες παραμέτρους για να εκπαιδεύσουμε το train set στον k-NN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "Xc6CBUjYtzrA",
    "outputId": "01cd5263-a645-4930-d12a-0c0181dd17d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy of k-NN: 79.811 %\n",
      "\n",
      "Confusion Matrix of k-NN:\n",
      " [[3021  668]\n",
      " [ 484 1533]]\n",
      "\n",
      "Classification Report of k-NN:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           g       0.86      0.82      0.84      3689\n",
      "           h       0.70      0.76      0.73      2017\n",
      "\n",
      "    accuracy                           0.80      5706\n",
      "   macro avg       0.78      0.79      0.78      5706\n",
      "weighted avg       0.80      0.80      0.80      5706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train_copy = m_scaler.fit_transform(x_train)\n",
    "x_test_copy = m_scaler.fit_transform(x_test)\n",
    "\n",
    "x_train_copy = applyPCA(x_train_copy, estimator_knn.best_params_['pca__n_components'])\n",
    "x_test_copy = applyPCA(x_test_copy, estimator_knn.best_params_['pca__n_components'])\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = estimator_knn.best_params_['kNN__n_neighbors'],\n",
    "                           metric = estimator_knn.best_params_['kNN__metric'],\n",
    "                           weights = estimator_knn.best_params_['kNN__weights'])                             \n",
    "\n",
    "start_time = time.time()\n",
    "knn.fit(x_train_copy,y_train_copy)\n",
    "fit_times['knn'] = time.time()-start_time\n",
    "\n",
    "start_time = time.time()\n",
    "npredictions['knn'] = knn.predict(x_test_copy)\n",
    "pred_times['knn'] = time.time()-start_time\n",
    "\n",
    "nbig_accuracies['knn'] = knn.score(x_test_copy,y_test)\n",
    "\n",
    "print(\"Classification Accuracy of k-NN:\",np.round(100*nbig_accuracies['knn'],3),\"%\")\n",
    "print(\"\\nConfusion Matrix of k-NN:\\n\",confusion_matrix(y_test,npredictions['knn']))\n",
    "print(\"\\nClassification Report of k-NN:\\n\",classification_report(y_test,npredictions['knn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cEkkwHzULXjK"
   },
   "source": [
    "Για τον MLP ακολουθούμε την ίδια προσέγγιση. Επειδή εδώ έχουμε περισσότερες παραμέτρους και το grid search θα είναι χρονοβόρο, θα δοκιμάσουμε να προσεγγίσουμε τις βέλτιστες τιμές σε περισσότερα σε 2 στάδια. Εδω παραθέτουμε το δεύτερο, αφού έχουμε προσδιορίσει τις διακριτές τιμές. Τα υπόλοιπα τρεξίματα παραλείπονται καθώς και μόνο η επανεκτέλεση προκειμένου να ολοκληρωθεί το notebook μπορεί να τρέχει υπερβολικά πολλές ώρες."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "8usPe7Kky2jA",
    "outputId": "88e6b153-a2c5-4977-8f3f-6a7cb5621d2a"
   },
   "outputs": [],
   "source": [
    "mlp_hidden_layers = [(i,2) for i in range(8,256,64)]\n",
    "mlp_activation = ['logistic']    # ['logistic','identity','tanh','relu']\n",
    "mlp_solver = ['lbfgs']           # ['lbfgs', 'sgd', 'adam']\n",
    "mlp_max_iter = np.arange(50,400,100)\n",
    "mlp_learning_rate = ['constant'] # ['constant', 'invscaling', 'adaptive']\n",
    "alpha = np.geomspace(1e-8,1e-3,5)\n",
    "n_components = np.arange(8,11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DXEHv-36tSeZ"
   },
   "source": [
    "Ορίζουμε το Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hjt6Wg2WtPX7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed: 18.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Συνολικός χρόνος fit και predict: 1120.19082570076 seconds\n",
      "Best parameters {'mlp__activation': 'logistic', 'mlp__alpha': 3.162277660168379e-06, 'mlp__hidden_layer_sizes': (136, 2), 'mlp__learning_rate': 'constant', 'mlp__max_iter': 350, 'mlp__solver': 'lbfgs', 'pca__n_components': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/klean/miniconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[('scaler', m_scaler),('selector', selector),('pca', pca),('mlp', mlp)], memory = 'tmp')\n",
    "estimator_mlp = GridSearchCV(pipe, dict(pca__n_components = n_components,\n",
    "                                            mlp__hidden_layer_sizes=mlp_hidden_layers,\n",
    "                                            mlp__activation=mlp_activation,\n",
    "                                            mlp__solver=mlp_solver,\n",
    "                                            mlp__alpha=alpha,\n",
    "                                            mlp__learning_rate=mlp_learning_rate,\n",
    "                                            mlp__max_iter=mlp_max_iter), cv=5, scoring='f1_macro', n_jobs=-1,\n",
    "                                                                                                   verbose=1)\n",
    "\n",
    "start_time = time.time()\n",
    "estimator_mlp.fit(x_train_sample,y_train_sample)\n",
    "preds = estimator_mlp.predict(x_test)\n",
    "print(\"Συνολικός χρόνος fit και predict: %s seconds\" % (time.time()-start_time))\n",
    "print(\"Best parameters\",estimator_mlp.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e7NJTW_3zQ_6"
   },
   "source": [
    "Έχοντας εντοπίσει τις βέλτιστες παραμέτρους για ένα μικρό δείγμα του train dataset, μπορούμε να επαναλάβουμε την διαδικασία για όλο το dataset με πολύ μικρότερο εύρος παραμέτρων, ωστόσο αυτό είναι αρκετά χρονοβόρο (20000 δείγματα) και με βάση τα παραπάνω αποτελέσματα και το είδος των παραμέτρων, δεν περιμένουμε σημαντική μεταβολή των αποτελεσμάτων. Συνεπώς, εφαρμόζουμε τις βέλτιστες παραμέτρους για να εκπαιδεύσουμε το MLP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/klean/miniconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy of MLP: 77.936 %\n",
      "\n",
      "Confusion Matrix of MLP:\n",
      " [[2799  890]\n",
      " [ 369 1648]]\n",
      "\n",
      "Classification Report of MLP:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           g       0.88      0.76      0.82      3689\n",
      "           h       0.65      0.82      0.72      2017\n",
      "\n",
      "    accuracy                           0.78      5706\n",
      "   macro avg       0.77      0.79      0.77      5706\n",
      "weighted avg       0.80      0.78      0.78      5706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train_copy = m_scaler.fit_transform(x_train)\n",
    "x_test_copy = m_scaler.fit_transform(x_test)\n",
    "\n",
    "x_train_copy = applyPCA(x_train_copy, estimator_mlp.best_params_['pca__n_components'])\n",
    "x_test_copy = applyPCA(x_test_copy, estimator_mlp.best_params_['pca__n_components'])\n",
    "\n",
    "mlp = MLPClassifier(solver=estimator_mlp.best_params_['mlp__solver'],\n",
    "                    alpha=estimator_mlp.best_params_['mlp__alpha'],\n",
    "                    hidden_layer_sizes=estimator_mlp.best_params_['mlp__hidden_layer_sizes'],\n",
    "                    random_state=1,\n",
    "                    activation=estimator_mlp.best_params_['mlp__activation'],\n",
    "                    learning_rate=estimator_mlp.best_params_['mlp__learning_rate'],\n",
    "                    max_iter=estimator_mlp.best_params_['mlp__max_iter']) \n",
    "\n",
    "start_time = time.time()\n",
    "mlp.fit(x_train_copy,y_train_copy)\n",
    "fit_times['mlp'] = time.time()-start_time\n",
    "\n",
    "start_time = time.time()\n",
    "npredictions['mlp'] = mlp.predict(x_test_copy)\n",
    "pred_times['mlp'] = time.time()-start_time\n",
    "\n",
    "nbig_accuracies['mlp'] = mlp.score(x_test_copy,y_test)\n",
    "\n",
    "print(\"Classification Accuracy of MLP:\",np.round(100*nbig_accuracies['mlp'],3),\"%\")\n",
    "print(\"\\nConfusion Matrix of MLP:\\n\",confusion_matrix(y_test,npredictions['mlp']))\n",
    "print(\"\\nClassification Report of MLP:\\n\",classification_report(y_test,npredictions['mlp']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qmgM2SlntpFD"
   },
   "source": [
    "#### 3. Bar Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "hCVDmyrktpFE",
    "outputId": "1ab96b92-1e0d-41b2-cb3f-4a3687e926da"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1_macros, f1_micros, labels = [],[],[]\n",
    "for clf in npredictions:  \n",
    "    f1_micros.append(f1_score(y_test,npredictions[clf],average='micro'))\n",
    "    f1_macros.append(f1_score(y_test,npredictions[clf],average='macro'))\n",
    "    labels.append(clf)\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, f1_micros, width, label='f1_micros')\n",
    "rects2 = ax.bar(x + width/2, f1_macros, width, label='f1_macros')\n",
    "\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Performance Comparison on F1-Score')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hTFasCUZtpFG"
   },
   "source": [
    "#### 4. Optimization Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "Bbepf_59tpFH",
    "outputId": "8bea337f-7ee4-4fe0-f8e7-47361161f2eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement for uniform : 0.01191728005608128\n",
      "Improvement for const_0 : 0.0\n",
      "Improvement for const_1 : 0.0\n",
      "Improvement for stratif : 0.010339992989835234\n",
      "Improvement for frequent : 0.0\n",
      "Improvement for gnb : 0.0\n",
      "Improvement for knn : 0.019803715387311627\n",
      "Improvement for mlp : 0.11777076761303895\n"
     ]
    }
   ],
   "source": [
    "for clf in nbig_accuracies: print(\"Improvement for\",clf,\":\",nbig_accuracies[clf]-big_accuracies[clf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ISLan-aPtpFK"
   },
   "source": [
    "#### 5. Discussion\n",
    "\n",
    "Όπως περιγράψαμε παραπάνω, ακολουθήσαμε μια bottom-up λογική για να επιλέξουμε τις βέλτιστες υπερπαραμέτρους pre-processing και training του dataset, ούτως ώστε να αυξήσουμε το accuracy της ταξινόμησης. Τα αποτελέσματα προφανώς είναι ταυτόσημα για τους dummy classifiers και τον Naive Bayes, οι οποίοι ταξινομητές δεν έχουν παραμέτρους προς βελτιστοποίηση. Aπό την άλλη, παρατηρούμε, όπως φαίνεται και στον optimization table, πως το tuning καταφέρνει να βελτιώσει αισθητά την επίδοση τόσο του k-NN όσο κυρίως του MLP Classifier που είχε και τις περισσότερες διαθέσιμες υπερπαραμέτρους (+11%). Όσον αφορά το classification accuracy, το καλύτερο ποσοστό το πετυχαίνει ο k-NN ο οποίος συνιστά πράγματι ένα ικανοποιητικό μοντέλο για το συγκεκριμένο task, με ποσοστό επιτυχίας κοντά στο 80%."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "MB4-B01(ntinos).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
